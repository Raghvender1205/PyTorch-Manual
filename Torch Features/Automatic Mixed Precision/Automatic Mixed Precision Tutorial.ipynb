{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Mixed Precision\n",
    "\n",
    "```torch.cuda.amp``` provides convenience methods for mixed precision, where some operations use ```torch.float32``` datatype and other operations use ```torch.float16 (half)```. Some ops, linear and convolution layers are much faster in ```torch.float16``` while other operations like reductions require the dynamic range of ```torch.float32```.\n",
    "\n",
    "`Mixed Precision` tries to match each op to its appropriate datatype, which can reduce the network's `runtime` and ```memory footprint```.\n",
    "\n",
    "```\"Automatic Mixed Precision Training\"``` uses ```torch.cuda.amp.autocast``` and ```torch.cuda.amp.GradScaler``` together. \n",
    "\n",
    "In this, we measure the performance of a Simple Network in ```default precision```, then adding ```autocast``` and ```GradScaler``` to run the same Net in `mixed Precision` with improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul 31 04:42:37 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 466.77       Driver Version: 466.77       CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   60C    P8     8W /  N/A |    255MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1420    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
      "|    0   N/A  N/A     18804    C+G   ...ser\\Application\\brave.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# My GPU's Architecture (Single GPU RTX 2060 6GB)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import gc\n",
    "\n",
    "start_time = None\n",
    "\n",
    "def start_timer():\n",
    "    global start_time\n",
    "    gc.collect()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "def end_timer(local_msg):\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"\\n\" + local_msg)\n",
    "    print(\"Total execution time = {:.3f} sec\".format(end_time - start_time))\n",
    "    print(\"Max memory used by tensors = {} bytes\".format(torch.cuda.max_memory_allocated()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Neural Network\n",
    "Neural Net with Linear Layers and ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(in_size, out_size, num_layers):\n",
    "    layers = []\n",
    "    for _ in range(num_layers - 1):\n",
    "        layers.append(torch.nn.Linear(in_size, in_size))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "    layers.append(torch.nn.Linear(in_size, out_size))\n",
    "    return torch.nn.Sequential(*tuple(layers)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```batch_size, in_size, out_size, and num_layers``` are chosen to be large enough to saturate the GPU with work. Typically, `mixed precision` provides the greatest speedup when the `GPU` is saturated. Small networks may be `CPU` bound, in which case mixed precision won’t improve performance. \n",
    "\n",
    "Sizes are also chosen such that linear layers’ participating dimensions are multiples of 8, to permit `Tensor Core` usage on `Tensor Core-capable GPUs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512 \n",
    "in_size = 4096\n",
    "out_size = 4096\n",
    "num_layers = 3\n",
    "num_batches = 50\n",
    "epochs = 3\n",
    "\n",
    "# Creates data in default precision.\n",
    "# The same data is used for both default and mixed precision trials below.\n",
    "# You don't need to manually change inputs' dtype when enabling mixed precision.\n",
    "data = [torch.randn(batch_size, in_size, device='cuda') for _ in range(num_batches)]\n",
    "targets = [torch.randn(batch_size, out_size, device='cuda') for _ in range(num_batches)]\n",
    "\n",
    "loss_fn = torch.nn.MSELoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.8316,  0.9260,  0.1173,  ...,  0.1361,  0.0983,  1.3280],\n",
       "         [-1.3049,  0.0830,  0.9496,  ..., -1.2548, -0.9005, -0.7632],\n",
       "         [-0.1109,  0.3389, -1.1462,  ..., -1.2532, -0.4346, -0.9692],\n",
       "         ...,\n",
       "         [-1.3842, -0.2880, -0.5669,  ...,  0.0857, -1.6083, -0.9542],\n",
       "         [-0.1475,  2.0280,  0.3341,  ...,  1.0582,  1.4145, -0.6916],\n",
       "         [-1.0510,  1.1050,  1.7701,  ..., -2.1392, -1.3736, -0.9380]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1558, -0.6074,  0.6044,  ...,  1.6116,  0.6203,  1.5289],\n",
       "         [ 0.6683, -1.3451, -1.6826,  ...,  1.6395, -1.0697, -0.0771],\n",
       "         [-1.1532, -1.2533, -1.5787,  ...,  1.2253,  0.6631, -0.4423],\n",
       "         ...,\n",
       "         [ 0.0622,  0.7171,  0.4504,  ..., -0.3777, -0.6482, -0.4877],\n",
       "         [ 0.1807,  0.6535, -1.3003,  ..., -0.3982,  0.3516,  0.7678],\n",
       "         [ 0.4318,  0.7493, -0.2879,  ..., -0.6993,  0.0477,  1.7387]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.2838,  0.1942,  0.7200,  ...,  0.0209, -1.1207,  1.2792],\n",
       "         [ 1.0876, -2.7359,  0.8299,  ...,  1.2672,  1.9602, -0.1693],\n",
       "         [ 1.0246, -0.9700, -1.8820,  ...,  1.9966, -0.1275,  0.5835],\n",
       "         ...,\n",
       "         [-0.1873,  1.8356, -3.0122,  ..., -0.3147,  1.8829,  0.4845],\n",
       "         [ 1.6362, -0.3401,  1.5969,  ..., -0.7985, -1.7653, -0.6675],\n",
       "         [-0.3911, -0.6333,  0.4401,  ..., -0.3533, -1.0502,  0.3278]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.2794,  0.7313,  0.7847,  ...,  0.3097, -0.7238, -0.8508],\n",
       "         [-0.5670, -1.4019,  0.3460,  ...,  1.5682, -0.4282,  0.0973],\n",
       "         [-1.5183, -0.7390, -0.6427,  ..., -0.6040,  1.3544,  0.4886],\n",
       "         ...,\n",
       "         [-0.5377, -0.7747, -1.2013,  ...,  0.1311,  0.1164,  2.2459],\n",
       "         [ 1.0556,  0.8729,  0.6355,  ..., -0.8043, -2.0287, -0.8245],\n",
       "         [-2.0721, -0.3847,  0.1042,  ...,  0.0748, -0.1162, -2.3289]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.2784,  0.3230,  0.0235,  ...,  0.0098, -0.6255, -0.1935],\n",
       "         [ 0.3290,  0.4276,  0.4519,  ..., -1.0562,  1.3514, -0.1272],\n",
       "         [-0.8036,  1.8069,  0.2833,  ...,  0.3296,  0.8234, -3.6350],\n",
       "         ...,\n",
       "         [-0.2407,  0.9481, -0.9585,  ...,  1.9742, -0.3461, -0.6198],\n",
       "         [-0.5296, -1.1882,  0.2837,  ...,  0.6370, -1.0651, -1.7336],\n",
       "         [-0.4724,  0.2360, -1.4046,  ...,  0.1091, -1.3769, -0.8267]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.2131,  0.9183,  0.3211,  ..., -1.4349, -1.9235,  0.8442],\n",
       "         [-0.6059,  0.3194, -0.2773,  ...,  0.2339, -1.3575, -1.3958],\n",
       "         [ 2.5106, -0.9373,  1.0330,  ...,  0.7791, -1.1849, -0.2988],\n",
       "         ...,\n",
       "         [-0.2826,  0.7233,  0.1834,  ...,  0.0827,  1.4899, -1.5161],\n",
       "         [ 0.6706,  0.2526, -0.2786,  ..., -1.7535, -0.3924, -0.5788],\n",
       "         [ 0.0959,  0.6004,  0.0920,  ...,  0.4003, -0.9100,  1.0852]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.9917e-01,  7.2222e-02, -2.4336e+00,  ..., -3.6881e-01,\n",
       "          -9.7842e-01,  3.2607e-01],\n",
       "         [ 2.5445e-01,  1.1097e+00, -5.0967e-01,  ...,  6.4394e-01,\n",
       "          -8.3789e-01,  7.0502e-02],\n",
       "         [-2.4141e+00,  1.1888e+00, -1.5388e-01,  ...,  4.2911e-01,\n",
       "          -8.3822e-01,  1.9861e-02],\n",
       "         ...,\n",
       "         [ 9.7677e-02, -3.0056e-01, -4.3185e-01,  ...,  2.0042e-01,\n",
       "           5.1999e-01,  1.6417e+00],\n",
       "         [-3.2636e-01, -7.1583e-01, -2.7582e-01,  ...,  2.6589e-01,\n",
       "          -1.6216e-03, -1.4869e+00],\n",
       "         [ 8.1078e-01, -1.9960e+00,  3.6885e-01,  ...,  3.3152e-01,\n",
       "           1.5880e+00, -1.3438e+00]], device='cuda:0'),\n",
       " tensor([[-1.1359,  0.2927, -0.2248,  ..., -0.3224, -0.8099, -0.6106],\n",
       "         [ 0.3009,  2.3028, -0.0970,  ..., -0.4297,  0.5845, -0.1309],\n",
       "         [ 0.8772,  0.3040, -0.4915,  ...,  0.8082, -0.7550,  1.2459],\n",
       "         ...,\n",
       "         [-0.2447, -0.9864,  1.3464,  ..., -1.6602,  0.0261, -0.2070],\n",
       "         [-0.2139, -0.7539,  0.2946,  ..., -0.1277, -0.1970, -0.8048],\n",
       "         [-0.1235, -0.0356, -0.9103,  ...,  0.0096,  0.7968,  0.0452]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0787, -1.5262,  0.8604,  ..., -1.0516, -0.3574,  0.1626],\n",
       "         [-1.6034, -1.1258,  0.8772,  ..., -2.1718,  0.5873, -0.6730],\n",
       "         [-0.0840, -0.8362, -0.9383,  ...,  1.0470,  0.5724,  1.3032],\n",
       "         ...,\n",
       "         [-0.7708, -0.9107,  0.2045,  ...,  0.9180,  1.3313, -1.3179],\n",
       "         [-0.0345,  0.9201, -0.2757,  ...,  0.0077,  0.6090, -2.4717],\n",
       "         [-1.8536,  0.7290, -0.7647,  ...,  1.7475, -1.5063,  0.8976]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.9752,  0.4236,  0.0576,  ...,  0.1024, -0.1448,  0.0044],\n",
       "         [ 1.2885,  1.7108, -0.4433,  ...,  1.1416,  0.0919,  1.1023],\n",
       "         [ 2.0431,  0.3968, -1.0457,  ...,  0.8622,  1.6895,  1.5025],\n",
       "         ...,\n",
       "         [ 0.0181, -0.4457,  0.4842,  ..., -1.1835,  0.1325, -0.1922],\n",
       "         [ 0.9831,  0.2287,  0.5485,  ...,  1.3640,  0.9936,  0.1846],\n",
       "         [ 2.3149, -0.1188,  1.2222,  ..., -0.1219,  0.3361, -0.2153]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 3.7408e-01, -1.9371e+00, -7.1191e-01,  ...,  1.2241e+00,\n",
       "          -8.0646e-01, -1.9129e+00],\n",
       "         [ 4.8050e-02,  6.6554e-04,  5.4473e-01,  ...,  8.0063e-01,\n",
       "          -8.2280e-01,  1.7188e+00],\n",
       "         [ 1.3074e+00,  1.1082e-01, -3.6464e-02,  ...,  1.6507e+00,\n",
       "           4.5571e-01, -6.4372e-01],\n",
       "         ...,\n",
       "         [ 1.1349e+00, -8.0091e-01,  2.5112e-01,  ...,  8.5200e-01,\n",
       "           2.0116e+00,  7.1718e-01],\n",
       "         [-1.5067e+00, -2.0778e+00, -3.9485e-01,  ...,  1.0035e+00,\n",
       "           9.2002e-01,  2.7356e-02],\n",
       "         [ 9.9296e-01, -1.0894e+00,  6.6892e-01,  ..., -2.6062e-01,\n",
       "           4.4527e-01, -1.6545e+00]], device='cuda:0'),\n",
       " tensor([[ 0.9665,  0.0301,  0.8325,  ...,  1.3043, -1.3714, -0.0712],\n",
       "         [-0.5749,  1.0666,  0.5543,  ...,  1.1361,  1.0416, -0.7431],\n",
       "         [ 0.9662, -0.0059, -0.5203,  ...,  0.7697,  0.3594, -0.1425],\n",
       "         ...,\n",
       "         [ 0.2449, -1.2640, -0.6868,  ..., -0.8576,  0.5877, -1.2660],\n",
       "         [-1.8729,  0.3841,  1.0102,  ..., -0.4747, -0.1317, -1.3809],\n",
       "         [ 1.1820,  0.6159,  0.6426,  ...,  0.6338, -1.3797, -0.2696]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.5539, -2.1246, -0.5471,  ...,  0.3839,  0.3513, -0.8483],\n",
       "         [ 0.1712, -0.0191, -1.5706,  ...,  0.6506, -0.2678,  1.1311],\n",
       "         [-0.5010, -0.6291, -1.0393,  ...,  1.4436,  1.0674, -1.2107],\n",
       "         ...,\n",
       "         [ 0.2237, -0.2253,  0.0048,  ..., -1.3966, -0.0692,  0.4431],\n",
       "         [ 1.9399,  0.1680,  0.3441,  ..., -1.8822, -0.1870,  1.1072],\n",
       "         [-0.5792,  0.8645,  0.0730,  ..., -1.9433, -1.4167,  0.4665]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.8375, -1.0411,  0.1228,  ..., -0.3255, -1.5900, -0.4602],\n",
       "         [ 0.0821,  0.2500,  1.6666,  ...,  0.5117, -1.0335, -1.0436],\n",
       "         [ 0.9150, -0.7104,  0.4864,  ...,  0.2088, -1.8064, -0.4724],\n",
       "         ...,\n",
       "         [ 0.6788, -0.3212, -1.6982,  ..., -2.0133, -0.0555, -0.7370],\n",
       "         [-0.6065, -1.0636,  1.3207,  ..., -0.2829, -0.8340,  0.8179],\n",
       "         [-0.3695,  0.4325,  0.4771,  ...,  0.5536, -0.4648, -1.2128]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.4474, -0.3454,  0.1795,  ..., -1.5823,  2.0020,  0.5697],\n",
       "         [-0.4297,  1.3803, -1.6661,  ...,  1.6045,  0.2920, -0.3809],\n",
       "         [ 0.5566,  0.4385,  0.2675,  ..., -0.2203, -0.7688, -0.3536],\n",
       "         ...,\n",
       "         [-0.0572,  0.5050,  2.2032,  ...,  2.4425,  0.4362,  1.3861],\n",
       "         [ 0.4018, -0.5272, -0.4919,  ..., -0.3074,  1.6552,  0.9521],\n",
       "         [ 0.8029,  0.1931, -1.4774,  ...,  1.0672,  0.5706, -0.7898]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.3520, -0.4064, -1.7280,  ...,  0.8343, -0.4788,  0.4577],\n",
       "         [-0.6682,  0.0349, -0.0833,  ...,  1.2664, -1.0806,  1.0531],\n",
       "         [-1.9826,  0.9092, -0.5163,  ..., -0.8248, -0.7528, -0.3500],\n",
       "         ...,\n",
       "         [ 0.2336,  0.0563,  0.1046,  ..., -0.4205, -0.4076, -0.4619],\n",
       "         [-0.4533, -2.3746,  0.2197,  ..., -0.7302, -0.4486,  0.0343],\n",
       "         [ 0.3387, -0.7486,  0.5064,  ..., -0.4821,  0.4195, -0.2990]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.4658, -0.0224,  0.1581,  ...,  0.1842,  0.9603,  0.4498],\n",
       "         [ 0.4956, -0.7790, -0.1363,  ...,  0.4507,  0.0941, -0.9533],\n",
       "         [-0.5321,  0.0572,  0.4553,  ...,  1.0473, -0.6716,  0.9618],\n",
       "         ...,\n",
       "         [-1.4390, -1.0727, -1.2136,  ...,  0.2184,  0.3227,  0.6581],\n",
       "         [-0.3932,  0.9558, -0.4278,  ..., -1.6078, -2.3445, -0.9069],\n",
       "         [ 0.7533,  0.2461, -0.3121,  ...,  0.9868,  1.6024, -0.6217]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.1952,  0.7400,  0.1062,  ...,  0.0532,  1.7920, -0.1387],\n",
       "         [ 0.5268,  0.3452, -1.3246,  ..., -1.1490,  0.7712, -0.9412],\n",
       "         [ 0.3003,  0.6493,  0.4115,  ...,  2.1390,  0.0841, -0.3163],\n",
       "         ...,\n",
       "         [ 1.4521,  0.4703, -0.6048,  ..., -0.8618,  0.0221,  0.5266],\n",
       "         [-0.6595, -0.3154, -0.6826,  ...,  2.2938, -0.7068, -1.2438],\n",
       "         [-0.9304,  0.6160, -0.7475,  ..., -0.7444,  1.5549, -0.2079]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.7474, -1.2017,  0.6917,  ...,  0.3545,  0.7220, -0.6543],\n",
       "         [ 1.7470, -1.1324, -0.6158,  ...,  1.2450, -0.1090, -0.2737],\n",
       "         [ 2.0775, -1.3697, -1.0787,  ...,  1.7595,  0.4299, -1.2940],\n",
       "         ...,\n",
       "         [ 0.7986, -2.0846,  1.2916,  ..., -2.2010, -1.2020,  1.3570],\n",
       "         [ 1.1761,  0.4752, -0.0839,  ...,  0.7231, -0.1252,  0.7866],\n",
       "         [-2.6280,  0.3052,  0.4103,  ..., -0.2751, -0.2212,  2.3956]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.6267, -0.7516, -1.0639,  ..., -1.2048, -0.6376,  1.2017],\n",
       "         [ 1.1552,  0.2586,  0.2322,  ...,  0.6263,  0.4145,  1.8762],\n",
       "         [ 1.0237, -0.2786,  0.8177,  ...,  0.3971,  0.3483,  0.7765],\n",
       "         ...,\n",
       "         [ 0.5762,  0.7048,  0.4403,  ..., -1.6789,  0.0419, -1.3458],\n",
       "         [-0.9425, -0.7165,  0.3356,  ..., -0.1175, -0.8898,  0.3535],\n",
       "         [ 0.0761, -0.1586, -0.6706,  ...,  2.1850, -0.1490,  0.1672]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.7090, -1.2704, -1.2666,  ..., -1.0917, -0.7494, -0.3504],\n",
       "         [ 1.9017, -0.4972, -1.8326,  ...,  0.3927, -0.1258,  0.9628],\n",
       "         [-0.7375,  0.6512,  0.3233,  ...,  0.0066,  0.3155, -0.7016],\n",
       "         ...,\n",
       "         [-2.2688, -0.3843, -1.3649,  ...,  1.2229, -0.6771,  0.2578],\n",
       "         [-2.9966,  0.6768, -1.9189,  ...,  0.7530,  0.5714,  0.0923],\n",
       "         [-0.5282, -0.8223, -0.6405,  ..., -0.0639,  0.3317, -1.6246]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.6650, -0.4321,  0.8186,  ...,  0.1723,  0.4680,  1.8675],\n",
       "         [-0.6914,  0.2976,  1.3602,  ...,  0.2217, -1.1845, -1.5914],\n",
       "         [-0.5206,  0.6141, -1.3887,  ...,  0.6571, -0.5067,  1.7237],\n",
       "         ...,\n",
       "         [ 0.2300,  0.7581,  1.2037,  ...,  1.1196, -0.3682, -0.9500],\n",
       "         [-0.0031, -0.3083, -1.2630,  ...,  1.2678, -0.0400, -1.3448],\n",
       "         [-0.7148,  0.2178,  1.1516,  ..., -0.8396,  0.0708, -0.4821]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.8080, -0.8978, -0.8737,  ...,  1.5549, -0.4524, -0.9414],\n",
       "         [ 0.2293, -0.5460,  0.9975,  ...,  0.3299,  0.6238, -0.5593],\n",
       "         [ 0.3863, -1.3217,  0.5796,  ...,  0.2576,  1.2494, -1.1976],\n",
       "         ...,\n",
       "         [ 0.9759,  0.9583,  0.3671,  ..., -0.2661,  0.5199,  0.0382],\n",
       "         [-0.6535,  0.0522,  0.9045,  ...,  0.2245,  0.1781,  0.8739],\n",
       "         [ 0.0926, -2.0584,  0.9211,  ...,  0.3039, -0.5719,  0.0321]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.4382,  0.4883, -0.3724,  ...,  1.1448,  0.1055,  0.6614],\n",
       "         [-0.2898,  0.0299, -1.4539,  ..., -1.2028, -1.1249, -1.2102],\n",
       "         [-1.2370,  0.7443, -0.9126,  ...,  0.0952,  0.5101, -0.6095],\n",
       "         ...,\n",
       "         [ 0.6221,  0.5642,  0.1568,  ..., -0.4990, -0.8397, -2.6306],\n",
       "         [-1.5210, -0.5931, -0.4288,  ...,  1.5914, -1.2272,  1.5803],\n",
       "         [-0.0971, -0.7184, -2.3423,  ..., -0.5164, -1.0438, -1.2969]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.5840,  0.0958, -0.0874,  ...,  0.1038, -0.5031,  1.0547],\n",
       "         [-2.7572,  0.8721,  1.3386,  ...,  0.1801, -0.7730, -0.7932],\n",
       "         [-1.0327, -0.5600, -1.1941,  ...,  1.3177,  1.5511,  0.8931],\n",
       "         ...,\n",
       "         [-0.7569, -0.3586, -1.2383,  ...,  0.4552, -1.1916,  0.9105],\n",
       "         [ 0.6734, -1.2325, -1.0602,  ..., -1.9412, -0.8688, -2.1400],\n",
       "         [-0.5014,  0.0666,  1.0443,  ..., -0.2300,  3.0636, -0.1595]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.3154, -0.4523, -0.8018,  ..., -0.3400, -1.0309,  0.2855],\n",
       "         [ 0.0961,  0.6434, -0.4859,  ..., -0.7180,  0.6818,  1.3905],\n",
       "         [ 0.6563,  0.4549, -0.2658,  ..., -0.5341, -0.0740,  1.4560],\n",
       "         ...,\n",
       "         [-0.4636, -0.5912, -0.9069,  ..., -1.6097, -0.6814,  1.1312],\n",
       "         [-1.5181, -1.0526,  0.4500,  ..., -3.0930, -1.2118,  0.9075],\n",
       "         [ 0.3413, -0.6082, -0.1544,  ...,  0.1552,  0.3275,  0.3710]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.3317,  0.7253,  0.9387,  ...,  0.1309,  1.0713, -1.3685],\n",
       "         [-0.7672,  0.9971, -0.7479,  ...,  1.8241,  0.1896,  0.4895],\n",
       "         [-0.2150, -0.5073,  0.5341,  ..., -0.2997, -0.6380, -0.9072],\n",
       "         ...,\n",
       "         [-0.4155, -0.6305,  1.8172,  ...,  0.2735,  0.4748,  0.3972],\n",
       "         [ 0.6775, -0.6112,  2.4823,  ...,  1.3430,  0.0645,  0.3071],\n",
       "         [-0.5029,  0.1395, -0.9304,  ..., -0.2895,  1.0233,  0.6125]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1735,  0.5815,  2.2301,  ...,  0.3198, -1.2456, -0.0294],\n",
       "         [ 1.8032, -0.0356, -1.0596,  ...,  0.3054, -1.1455, -0.9608],\n",
       "         [ 1.1640, -0.9266,  0.1376,  ..., -0.5038, -0.9551,  0.3986],\n",
       "         ...,\n",
       "         [ 1.0518, -0.0863,  0.6558,  ...,  1.6029,  1.6184,  2.3142],\n",
       "         [ 1.8716, -1.8565,  0.9304,  ...,  2.0628, -0.8791, -0.2433],\n",
       "         [-0.3807, -0.1196, -0.6046,  ...,  0.1019, -0.0962,  0.4389]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.2399, -0.2292, -2.2058,  ..., -1.8527, -0.3617,  1.5835],\n",
       "         [ 1.5305,  0.5296, -0.1922,  ...,  0.0304,  0.5007, -1.5178],\n",
       "         [ 0.8166,  0.9801, -0.0918,  ...,  1.8422,  1.1913, -0.4952],\n",
       "         ...,\n",
       "         [-0.5226, -1.0411, -1.6800,  ..., -1.8502,  1.3325, -1.4678],\n",
       "         [-0.2926,  1.3389, -1.6131,  ..., -2.2817, -1.2206, -0.5228],\n",
       "         [-1.2744, -0.3796, -0.2067,  ..., -0.8643, -0.0636, -0.5157]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1100, -0.6718, -1.7670,  ..., -0.1647, -0.5591, -0.5911],\n",
       "         [-1.3949,  0.9834, -0.2810,  ..., -0.3490,  1.6841,  0.4569],\n",
       "         [ 0.8654, -0.0070,  0.0409,  ...,  0.7195,  0.6532,  0.7023],\n",
       "         ...,\n",
       "         [-1.1825,  0.2963,  2.1060,  ...,  0.0199,  0.9039,  0.0418],\n",
       "         [ 1.2315, -0.0540, -2.5387,  ...,  0.3583,  0.0033,  0.3711],\n",
       "         [ 0.6235,  0.1510,  0.3196,  ...,  1.0228, -1.3926,  0.1147]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.4754,  0.0210, -0.2545,  ...,  0.2019,  0.2468,  1.0845],\n",
       "         [ 1.0927,  2.0863,  1.3148,  ..., -0.2253, -0.3145, -0.1486],\n",
       "         [-0.3086,  0.3713,  1.1529,  ..., -0.9518, -0.8260, -0.3988],\n",
       "         ...,\n",
       "         [-0.0877, -1.1938, -0.6401,  ...,  0.3400, -1.2642,  0.8219],\n",
       "         [ 2.9605, -0.0460, -1.1157,  ...,  0.4571,  0.2723, -0.7105],\n",
       "         [-1.1566,  1.1218,  0.0341,  ...,  0.2494,  2.2393, -0.6425]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.0716,  0.0413, -0.8697,  ..., -1.0160,  1.5818,  0.9883],\n",
       "         [-1.0130, -0.3120,  0.5132,  ..., -1.2144, -0.7847,  2.5679],\n",
       "         [ 0.0223,  0.3598,  0.7471,  ..., -0.1530,  1.0570,  0.7268],\n",
       "         ...,\n",
       "         [-1.2226, -0.6616,  0.0753,  ...,  1.5916,  0.5222, -0.5739],\n",
       "         [-0.1840,  0.7016, -0.6811,  ...,  0.0175, -0.0582, -1.1787],\n",
       "         [ 0.2482,  0.7324, -0.1955,  ..., -1.8615,  0.7438,  0.2755]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.5790,  0.2867,  0.9225,  ..., -0.5185, -0.3848,  0.8622],\n",
       "         [ 0.4747, -0.4006, -0.3192,  ...,  0.4225, -1.0232,  0.7398],\n",
       "         [ 0.2486, -0.6039, -0.0095,  ..., -0.5344,  0.5747, -0.6366],\n",
       "         ...,\n",
       "         [ 2.1864, -0.2815, -0.2756,  ...,  0.0605,  0.6156,  0.4908],\n",
       "         [-0.9381, -1.7109,  0.9594,  ...,  0.0109, -0.0973, -0.2856],\n",
       "         [-0.1996,  0.6569,  0.0742,  ...,  0.7139,  1.3650,  1.1589]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.3076,  0.5338, -0.9897,  ..., -1.5186,  0.9248, -0.9142],\n",
       "         [ 0.5956,  1.3382,  1.0568,  ..., -1.7971,  0.2463,  0.5171],\n",
       "         [ 1.7870, -1.1162,  1.8575,  ..., -1.6660, -0.3776,  0.2266],\n",
       "         ...,\n",
       "         [ 0.5858,  1.0578,  0.0774,  ...,  1.3299, -1.5579, -0.5016],\n",
       "         [ 0.0790,  1.7199, -2.1787,  ..., -1.0815, -1.9982,  0.8264],\n",
       "         [ 1.1035,  1.0619, -0.7130,  ...,  1.2622,  0.0629,  1.0130]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.8723, -0.1051, -0.0111,  ...,  0.4837,  0.4542,  0.3446],\n",
       "         [-2.2248,  0.2822, -0.8215,  ..., -0.4661,  0.1857,  0.5912],\n",
       "         [-1.5346,  0.8646,  0.1707,  ..., -0.8781,  0.0667,  0.9677],\n",
       "         ...,\n",
       "         [-0.6963,  0.2135,  0.8262,  ..., -1.4453, -0.7167,  1.3756],\n",
       "         [-1.2052, -1.7060, -1.5528,  ..., -0.9560,  0.3837, -0.7333],\n",
       "         [-1.0150, -0.3881,  1.0307,  ..., -0.1486, -1.5305, -0.9123]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.7712, -1.6218,  0.4476,  ...,  0.1355, -0.9047,  2.0419],\n",
       "         [-1.3738, -0.6890,  0.2416,  ...,  1.3274, -0.5396,  0.0865],\n",
       "         [-0.0688,  0.4983, -0.9038,  ...,  1.1871,  0.2199, -0.0727],\n",
       "         ...,\n",
       "         [ 0.4567, -3.4218,  0.8746,  ..., -0.1974,  0.2182, -1.9521],\n",
       "         [-1.0366, -0.0897,  0.0857,  ...,  0.9499,  1.0111,  0.2352],\n",
       "         [ 0.5442,  1.0790,  0.5908,  ..., -0.4747,  0.4501,  0.0664]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 7.5696e-02,  3.8739e-01, -2.0919e-02,  ...,  1.1716e+00,\n",
       "          -1.8723e+00,  1.0910e+00],\n",
       "         [ 1.9769e-01,  5.3099e-01, -6.6103e-01,  ..., -2.0438e+00,\n",
       "          -1.3132e+00, -2.6608e+00],\n",
       "         [ 9.7763e-01,  1.4834e+00, -1.4818e+00,  ...,  2.0129e+00,\n",
       "          -2.3137e-01,  3.0881e-01],\n",
       "         ...,\n",
       "         [-7.1647e-01, -4.9407e-01, -3.9386e-01,  ...,  2.7305e-02,\n",
       "           2.8661e-01, -2.0130e-01],\n",
       "         [-8.7436e-01,  8.1063e-01,  2.3760e-02,  ..., -3.8303e-02,\n",
       "          -1.4127e+00, -8.4710e-01],\n",
       "         [-3.0809e-01,  1.4000e+00, -1.2899e+00,  ..., -1.0870e-03,\n",
       "           1.3280e+00,  1.2334e+00]], device='cuda:0'),\n",
       " tensor([[-1.5528, -1.9376, -0.5556,  ..., -0.8904, -1.1481, -0.6147],\n",
       "         [ 0.0604, -1.2873, -0.9438,  ...,  0.5116,  0.3726,  1.0157],\n",
       "         [ 2.7465, -0.2167, -1.3288,  ...,  0.1500, -0.8886,  1.5257],\n",
       "         ...,\n",
       "         [ 2.1079,  0.4095, -1.2113,  ..., -0.0736,  2.2521, -0.3769],\n",
       "         [ 0.8265,  0.1950, -0.9954,  ...,  1.3311, -0.3726, -0.3116],\n",
       "         [-0.4518,  1.1462, -1.3957,  ..., -0.1542,  1.0409, -0.2604]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1905,  0.1909, -0.1581,  ...,  1.0751, -0.0912, -0.1617],\n",
       "         [ 0.0190,  1.5963, -0.3797,  ..., -1.5312, -0.4117,  0.1226],\n",
       "         [-0.0417, -0.4792,  0.1405,  ...,  1.3787,  0.0749, -0.8184],\n",
       "         ...,\n",
       "         [-1.1708,  1.7001, -0.2791,  ..., -0.1006, -0.6984,  0.2035],\n",
       "         [ 0.1745,  0.0560, -0.4272,  ...,  1.8914,  0.1958, -0.4183],\n",
       "         [ 0.7715, -0.4978,  0.2462,  ...,  1.5166,  1.2361, -0.6950]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.4452, -0.6468, -0.8356,  ..., -1.0426, -1.3887, -1.9220],\n",
       "         [ 1.5363, -0.7977,  0.9911,  ...,  1.3545, -0.8544, -0.3178],\n",
       "         [-0.2443,  0.2410,  1.3308,  ..., -1.1794, -0.3937, -0.1271],\n",
       "         ...,\n",
       "         [-0.8978,  0.5442,  0.0968,  ...,  0.5154,  2.4345, -0.3942],\n",
       "         [-0.4000,  0.6772, -0.7941,  ..., -1.4855, -2.5744,  0.9055],\n",
       "         [-0.7197, -0.8119,  1.0593,  ...,  0.9366,  0.3565, -0.4534]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.2498,  1.1165, -0.7063,  ..., -0.8992, -0.6541, -2.4925],\n",
       "         [-0.3273,  0.0182, -1.7661,  ..., -0.4024, -0.6291, -0.7532],\n",
       "         [-1.6927, -0.0044, -1.2823,  ..., -0.2968, -1.3278, -0.3131],\n",
       "         ...,\n",
       "         [ 0.5317, -1.7740, -0.2162,  ...,  0.0428,  2.5575,  0.2347],\n",
       "         [ 1.4541, -0.3320, -0.3012,  ...,  0.7852, -0.4325,  1.1017],\n",
       "         [-0.5001,  1.6054, -0.7501,  ..., -0.7410,  0.2611, -0.2445]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.1096,  0.7160,  1.5540,  ..., -0.3600,  0.0570, -1.2149],\n",
       "         [-0.0913,  1.3324,  0.7664,  ..., -0.7112,  0.1775,  0.8536],\n",
       "         [-1.1199,  0.0565,  0.8089,  ...,  0.2979,  0.5449, -0.1970],\n",
       "         ...,\n",
       "         [ 0.7981, -1.4490, -1.3207,  ...,  0.1603,  0.1283, -0.4022],\n",
       "         [-0.9659, -0.5917, -0.7989,  ...,  0.1011, -1.4087, -0.4655],\n",
       "         [ 0.9241, -0.8586, -0.9840,  ...,  0.1430,  0.4625, -0.6771]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.5573, -1.5631, -0.0346,  ...,  0.0355,  0.4702, -0.2059],\n",
       "         [-1.0144, -0.2772,  0.2790,  ..., -2.0924,  0.8251,  0.0674],\n",
       "         [-0.5913,  1.3511, -0.0261,  ..., -0.6946, -2.3250, -0.7807],\n",
       "         ...,\n",
       "         [-0.7304,  1.7628,  0.0963,  ...,  0.2431, -0.2631,  1.4177],\n",
       "         [-0.7899, -0.3243, -0.6323,  ...,  0.2284, -0.1196, -0.8977],\n",
       "         [-1.4914,  0.9522,  0.0805,  ...,  0.5438,  0.1128, -0.1552]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.2817, -0.2219, -2.0581,  ..., -0.2295, -0.2235, -0.1195],\n",
       "         [-1.9182, -1.0038, -0.7273,  ...,  0.5673,  1.1161,  1.7445],\n",
       "         [-0.9448,  0.1856,  0.1276,  ...,  0.4823,  0.8104,  1.4035],\n",
       "         ...,\n",
       "         [-1.4987,  0.7268,  1.7043,  ..., -0.1441,  0.8819, -0.3937],\n",
       "         [-0.0061,  0.0177,  0.1297,  ..., -0.8512,  0.7238,  0.8633],\n",
       "         [-1.3437,  0.6316,  0.9273,  ..., -1.5680,  0.9721,  0.3405]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0505, -0.4209,  0.7968,  ...,  0.3304, -1.4051,  0.4604],\n",
       "         [ 0.6938,  1.5429,  0.7933,  ...,  1.3532,  1.6718,  0.2382],\n",
       "         [ 0.3305,  2.0550, -1.7013,  ..., -0.5838,  0.5198,  0.2714],\n",
       "         ...,\n",
       "         [-0.9162,  0.0921, -1.8958,  ..., -1.4448,  0.4469, -0.8950],\n",
       "         [ 1.2703,  0.5208, -0.0082,  ...,  0.6269, -0.5268, -0.4379],\n",
       "         [ 0.5201,  0.3783,  0.2052,  ..., -0.9026,  0.7255,  0.4744]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.5261, -0.2608,  0.6281,  ...,  1.2272,  0.8831, -0.2724],\n",
       "         [ 0.5487,  0.1793, -0.2967,  ..., -0.4547, -1.0792,  0.8736],\n",
       "         [-1.7346, -0.9814, -0.5799,  ..., -2.0930, -1.3770,  2.1681],\n",
       "         ...,\n",
       "         [ 0.2104, -1.5423,  0.4720,  ..., -2.0189, -0.0228, -0.9379],\n",
       "         [-1.2810,  0.1663, -1.8411,  ...,  0.2883, -1.3341, -0.4622],\n",
       "         [-1.6308,  0.0433,  0.7598,  ...,  0.3598, -0.0922, -0.3517]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.0326, -1.5170,  0.7294,  ..., -1.3031, -1.1849,  2.1104],\n",
       "         [ 0.8889, -0.2526, -0.0297,  ...,  0.5097, -0.9727, -1.7469],\n",
       "         [ 1.2672,  1.1815, -0.6182,  ...,  1.4130, -1.4069,  0.7258],\n",
       "         ...,\n",
       "         [-0.5156,  1.6084, -0.3435,  ..., -0.4159,  0.8527,  0.8951],\n",
       "         [ 1.3033, -1.0567, -0.9718,  ...,  1.3298, -0.0315, -1.6472],\n",
       "         [ 1.1319,  0.1521, -0.7419,  ..., -0.8316, -0.6745,  1.3551]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.5255, -0.3649, -0.9470,  ...,  0.7225, -0.8451,  0.3033],\n",
       "         [ 1.4994, -0.6991,  0.1477,  ...,  0.8214, -0.1765,  0.6999],\n",
       "         [ 0.4694,  0.8461, -1.2220,  ...,  0.3142, -0.8758,  0.2986],\n",
       "         ...,\n",
       "         [-0.0767,  0.3807, -1.2200,  ...,  1.0602,  1.4164,  0.3242],\n",
       "         [-1.1525,  0.8319, -0.9091,  ...,  0.2194, -2.8376,  0.3440],\n",
       "         [ 0.1487, -0.0082, -0.5833,  ...,  0.8204,  0.9709,  0.3050]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.2960,  1.3409,  1.7692,  ..., -0.3981,  0.6966, -2.0426],\n",
       "         [ 0.2007,  0.5917,  0.2282,  ...,  0.1658, -0.0180,  1.7884],\n",
       "         [-0.9833,  0.7398, -0.5339,  ..., -0.3924, -1.4184,  0.3763],\n",
       "         ...,\n",
       "         [-0.1746, -0.7736, -0.2580,  ..., -0.0972, -0.5887, -0.8931],\n",
       "         [-0.7248, -0.3669, -0.0218,  ...,  0.7079, -1.1602, -1.0234],\n",
       "         [ 2.0384,  0.0986, -1.3637,  ...,  0.1773, -0.2285, -0.1399]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.4241, -2.5132, -0.1461,  ...,  0.4923, -1.9588, -2.3520],\n",
       "         [-0.4711, -1.2881, -0.2916,  ...,  0.9166,  0.6663, -0.4305],\n",
       "         [ 1.3448, -0.8387, -2.2193,  ..., -0.5744, -0.7388, -0.1043],\n",
       "         ...,\n",
       "         [-1.3118, -1.6093, -1.8915,  ..., -0.0981, -1.0340, -0.5808],\n",
       "         [-0.4703,  0.4382, -1.2354,  ...,  1.5827,  1.1992, -1.1077],\n",
       "         [ 0.3657, -0.7267,  0.3634,  ..., -0.1808,  0.2657, -1.2689]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul 31 04:52:03 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 466.77       Driver Version: 466.77       CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   62C    P2    28W /  N/A |   1844MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1420    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
      "|    0   N/A  N/A     12140      C   ...conda3\\envs\\ML\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     18804    C+G   ...ser\\Application\\brave.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# At this time\n",
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Precision\n",
    "Without ```torch.cuda.amp```, the net will execute all ops in `default precision` (```torch.float32```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torch\\cuda\\memory.py:260: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default Precision: \n",
      "Total execution time = 8.063 sec\n",
      "Max memory used by tensors = 1367458816 bytes\n"
     ]
    }
   ],
   "source": [
    "net = make_model(in_size, out_size, num_layers)\n",
    "opt = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "start_timer()\n",
    "for epoch in range(epochs):\n",
    "    for input, target in zip(data, targets):\n",
    "        output = net(input)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad() # set_to_none=True\n",
    "end_timer(\"Default Precision: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul 31 04:56:00 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 466.77       Driver Version: 466.77       CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   64C    P2    29W /  N/A |   2536MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1420    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
      "|    0   N/A  N/A     12140      C   ...conda3\\envs\\ML\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     18804    C+G   ...ser\\Application\\brave.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Autocast\n",
    "\n",
    "Instances of ```torch.cuda.amp.autocast``` serve as context managers that allow some regions here to run in ```mixed precision```.\n",
    "\n",
    "In these regions, `CUDA` ops run in a `dtype` chosen by ```autocast``` to improve performance while maintaining accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0):\n",
    "    for input, target in zip(data, targets):\n",
    "        # Run Forward Pass under Autocast\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = net(input)\n",
    "            # output -> torch.float16 becoz Linear Layers autocast to Float16\n",
    "            assert output.dtype is torch.float16\n",
    "            \n",
    "            loss = loss_fn(output, target)\n",
    "            # loss -> torch.float32 becoz MSELoss layers autocast to Float32\n",
    "            assert loss.dtype is torch.float32\n",
    "        \n",
    "        # Exit AutoCast after backward pass\n",
    "        # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding GradScaler\n",
    "\n",
    "```Gradient Scaling``` helps prevent gradients with small magnitudes from ```flushing to zero``` when training with ```mixed precision```.\n",
    "\n",
    "```torch.cuda.amp.GradScaler``` performs the steps of ```gradient Scaling```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructs scaler once, at the beginning of the convergence run, using default args.\n",
    "# The same GradScaler instance should be used for the entire convergence run.\n",
    "# If you perform multiple convergence runs in the same script, each run should use\n",
    "# a dedicated fresh GradScaler instance.  GradScaler instances are lightweight.\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(0): # Not Now\n",
    "    for input, target in zip(data, targets):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = net(input)\n",
    "            loss = loss_fn(output, target)\n",
    "            \n",
    "        # Scales losses, Calls backward() on scaled loss to create scaled gradients\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "        # otherwise, optimizer.step() is skipped.\n",
    "        scaler.step(opt)\n",
    "        \n",
    "        # Updates the scale for next iter.\n",
    "        scaler.update()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Automatic Mixed Precision (Combined Autocast and GradScaler)\n",
    "\n",
    "In this, there is an optional argument ```enabled``` to ```autocast``` and ```GradScaler```. If ```False```, `autocast` and `GradScaler`'s calls become no-ops. This allows switching between `default precision and mixed precision` without if/else statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torch\\cuda\\memory.py:260: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Automatic Mixed Precison: \n",
      "Total execution time = 3.298 sec\n",
      "Max memory used by tensors = 1803759616 bytes\n"
     ]
    }
   ],
   "source": [
    "use_amp = True # Optional Argument\n",
    "\n",
    "net = make_model(in_size, out_size, num_layers)\n",
    "opt = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "start_timer()\n",
    "for epoch in range(epochs):\n",
    "    for input, target in zip(data, targets):\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            output = net(input)\n",
    "            loss = loss_fn(output, target)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "end_timer(\"Automatic Mixed Precison: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul 31 14:05:57 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 466.77       Driver Version: 466.77       CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   52C    P2    26W /  N/A |   2957MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1420    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
      "|    0   N/A  N/A     12140      C   ...conda3\\envs\\ML\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     12476    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     18804    C+G   ...ser\\Application\\brave.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting/Modifying Graphs \n",
    "\n",
    "All gradients produced by ```scaler.scale(loss).backward()``` are scaled. If we wish to ```inspect or modify``` the parameters. ```.grad``` attributes between ```backward()``` and ```scaler.step(optimizer)```, but first we should `unscale` them using ```scaler.unscale_(optimizer)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0): \n",
    "    for input, target in zip(data, targets):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = net(input)\n",
    "            loss = loss_fn(output, target)\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscales the gradients of optimizer's assigned params in-place\n",
    "        scaler.unscale_(opt)\n",
    "\n",
    "        # Since the gradients of optimizer's assigned params are now unscaled, clips as usual.\n",
    "        # You may use the same value for max_norm here as you would without gradient scaling.\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.1)\n",
    "\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        opt.zero_grad() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
