{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Semantics\n",
    "\n",
    "`torch.cuda` is used to set up and run CUDA operations. It keeps track of the currently selected `GPU`, and all CUDA tensors you allocate will be default be created on that `device`. The selected device can be changed with a `torch.cuda.device` context manager.\n",
    "\n",
    "However, once a tensor is allocted, you can do operations on it irrespective of the selected device, and the results will be always placed is on the same device as the tensor.\n",
    "\n",
    "Cross-GPU operations are not allowed by default, with the exception of `copy_()` and other methods with copy-like functionality such as `to()` and `cuda()`. Unless you enable `peer-to-peer` memory access, any attempts to launch ops on tensors spread accross different devices will raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "x = torch.tensor([1., 2.], device=cuda)\n",
    "# x.device is device(type='cuda', index=0)\n",
    "y = torch.tensor([1., 2.]).cuda()\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    # allocates a tensor on GPU 1\n",
    "    a = torch.tensor([1., 2.], device=cuda)\n",
    "\n",
    "    # transfers a tensor from CPU to GPU 1\n",
    "    b = torch.tensor([1., 2.]).cuda()\n",
    "    # a.device and b.device are device(type='cuda', index=1)\n",
    "\n",
    "    # You can also use ``Tensor.to`` to transfer a tensor:\n",
    "    b2 = torch.tensor([1., 2.]).to(device=cuda)\n",
    "    # b.device and b2.device are device(type='cuda', index=1)\n",
    "\n",
    "    c = a + b\n",
    "    # c.device is device(type='cuda', index=1)\n",
    "\n",
    "    z = x + y\n",
    "    # z.device is device(type='cuda', index=0)\n",
    "\n",
    "    # even within a context, you can specify the device\n",
    "    # (or give a GPU index to the .cuda call)\n",
    "    d = torch.randn(2, device=cuda)\n",
    "    e = torch.randn(2).to(cuda)\n",
    "    f = torch.randn(2).cuda(cuda)\n",
    "    # d.device, e.device, and f.device are all device(type='cuda', index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
